{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94274728",
   "metadata": {},
   "source": [
    "### Parcialito 1 - Federico del Mazo - 100029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d491884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../Shared/World.csv', header=0, names=[\"source\", \"target\", \"_weight\"])\n",
    "Graphtype = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(df, create_using=Graphtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eda3a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "1. Determinar:\n",
    "  a. El diámetro de la red: {nx.diameter(G)}\n",
    "  b. El grado promedio de la red: {sum([n[1] for n in G.degree()]) / len(G):.2f}\n",
    "  c. El coeficiente de clustering promedio de la red: {nx.average_clustering(G):.2f}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cb142b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "2. Indicar si existe algún tipo de Homofilia y qué tipo de homofilia es. Si no hay homofilia por ningún criterio, explicar. Justificar detalladamente.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656742cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Consigamos atributos de paises -> https://www.kaggle.com/datasets/sudalairajkumar/undata-country-profiles\n",
    "df2 = pd.read_csv('country_profile_variables.csv', header=0)\n",
    "\n",
    "# Quedemonos con solo los atributos que voy a analizar, para no agregar ruido al df\n",
    "df2 = df2[['country', 'Region', 'Population in thousands (2017)', 'GDP per capita (current US$)']]\n",
    "\n",
    "# Agrego a manopla el atributo continente, que es al que más fé le tengo para la homofilia\n",
    "region_to_continent = {'SouthernAsia': 'Asia', 'SouthernEurope': 'Europe', 'NorthernAfrica': 'Africa', 'Polynesia': 'Oceania', 'MiddleAfrica': 'Africa', 'Caribbean': 'CentralAmerica', 'SouthAmerica': 'SouthAmerica', 'WesternAsia': 'Asia', 'Oceania': 'Oceania', 'WesternEurope': 'Europe', 'EasternEurope': 'Europe', 'CentralAmerica': 'CentralAmerica', 'WesternAfrica': 'Africa', 'NorthernAmerica': 'NorthernAmerica', 'SouthernAfrica': 'Africa', 'South-easternAsia': 'Asia', 'EasternAfrica': 'Africa', 'NorthernEurope': 'Europe', 'EasternAsia': 'Asia', 'Melanesia': 'Oceania', 'Micronesia': 'Oceania', 'CentralAsia': 'Asia'} \n",
    "df2['Continent'] = df2['Region'].map(region_to_continent)\n",
    "\n",
    "# Bucketeo un par de atributos, así es más facil de analizar\n",
    "to_bucket = ['Population in thousands (2017)', 'GDP per capita (current US$)']\n",
    "for attr in to_bucket:\n",
    "    df2[attr] = pd.qcut(df2[attr], q=5).astype('str')\n",
    "\n",
    "# Lamentablemente, nuestros 2 datasets no son perfectamente compatibles. \n",
    "# Hay 13 paises con un nombre en uno, y otro nombre en otro\n",
    "# También hay 16 paises de los que no tenemos datos\n",
    "aliases = {\"China, Hong Kong SAR\": \"Hong Kong\", \"Micronesia (Federated States of)\": \"Micronesia\", \"Czechia\": \"Czech Republic\", \"Democratic People's Republic of Korea\": \"South Korea\", \"Russian Federation\": \"Russia\", \"The former Yugoslav Republic of Macedonia\": \"Macedonia\", \"Iran (Islamic Republic of)\": \"Iran\", \"Venezuela (Bolivarian Republic of)\": \"Venezuela\", \"Brunei Darussalam\": \"Brunei\", \"Falkland Islands (Malvinas)\": \"Falkland Islands\", \"Syrian Arab Republic\": \"Syria\", \"Wallis and Futuna Islands\": \"Wallis and Futuna\", \"Republic of Korea\": \"North Korea\"}\n",
    "df2 = df2.set_index('country').rename(index = aliases)\n",
    "\n",
    "# Convierto mi df en un diccionario de atributos, y se lo plasmo a mi grafo\n",
    "attributes = df2.to_dict('index')\n",
    "nx.set_node_attributes(G, attributes)\n",
    "\n",
    "# Para un análisis de homofilia más puro, quiero que todos mis nodos tengan atributos seteados\n",
    "# Borro los 16 paises que me quedaron colgados sin data\n",
    "to_remove = []\n",
    "for n in G.nodes(data=True):\n",
    "    if not n[1]: to_remove.append(n[0])\n",
    "\n",
    "for n in to_remove: G.remove_node(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aae239",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Funciones para calcular la homofilia según atributo\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from itertools import combinations_with_replacement\n",
    "\n",
    "# Dado un atributo, devuelve un diccionario con todas las proporciones de aristas entre atributos.\n",
    "# En el ejemplo de la sección 4.1 de Networks, Crowds, and Markets, el resultado sería:\n",
    "#   {(Male, Male): 11/18, (Female, Male): 5/18, (Female, Female): 3/18}\n",
    "def get_attr_edges_real_fraction(G, attr):\n",
    "    edges = []\n",
    "    for e in G.edges():\n",
    "        attr1, attr2 = G.nodes[e[0]][attr], G.nodes[e[1]][attr]    \n",
    "        # we sort the attributes to make sure a B-A edge counts as an A-B one\n",
    "        edges.append(tuple(sorted([attr1,attr2])))\n",
    "    count = Counter(edges)\n",
    "    total_edges = nx.number_of_edges(G)\n",
    "    return {k: v/total_edges for k,v in count.items()}\n",
    "\n",
    "# Dado un atributo, devuelve un diccionario con todas las proporciones de aristas ideales si no hubiese homofilia.\n",
    "# Es decir, de todos los nodos con sus distintas probabilidades de tomar algun valor del atributo,\n",
    "#   la arista entre dos nodos del mismo atributo tendrá p*p / cant_nodos de aparecer,\n",
    "#   y la arista entre dos nodos de distinto atributo tendrá 2*p*q / cant_nodos de aparecer,\n",
    "# En el ejemplo de la sección 4.1 de Networks, Crowds, and Markets, el resultado sería:\n",
    "#   {(Male, Male): 4/9, (Female, Male): 4/9, (Female, Female): 1/9}\n",
    "def get_attr_edges_expected_fraction(G, attr):\n",
    "    attr_count = Counter(nx.get_node_attributes(G, attr).values())\n",
    "    total_nodes = nx.number_of_nodes(G)\n",
    "    attr_fraction = {k: v/total_nodes for k,v in attr_count.items()}\n",
    "\n",
    "    attr_combinations = combinations_with_replacement(attr_count.keys(), 2)\n",
    "    count = {}\n",
    "    for attr1, attr2 in attr_combinations:\n",
    "        if (attr1 == attr2):\n",
    "            expected_fraction = attr_fraction[attr1] * attr_fraction[attr2]\n",
    "        else:\n",
    "            expected_fraction = attr_fraction[attr1] * attr_fraction[attr2] * 2\n",
    "        count[tuple(sorted([attr1, attr2]))] = expected_fraction\n",
    "    return count\n",
    "    \n",
    "\n",
    "# Dado un atributo, devuelve un porcentaje que simboliza cuan homofílico respecto del atributo es el grafo\n",
    "# Es decir, en un grafo donde no hay nada de homofilia, este valor será 0%,\n",
    "#   y en un grafo donde hay toda la homofilia del mundo, este valor será 100%\n",
    "# (ojo, este valor es exactamente el inverso al que aprendimos en clase!)\n",
    "# Al lidiar con atributos multivariados, el resultado final será un promedio ponderado de todos los\n",
    "#   coeficientes de valor_real/valor_esperado para cada arista que junta un par de atributos.\n",
    "# La ponderación de cada arista es la cantidad total de nodos que pertenecen a los atributos que une.\n",
    "# En el ejemplo de la sección 4.1 de Networks, Crowds, and Markets, el resultado sería:\n",
    "#   1 - 0.62 ==> 38%\n",
    "def homophily_percentage(G, attr):\n",
    "    attributes = Counter(nx.get_node_attributes(G, attr).values())\n",
    "    expected = get_attr_edges_expected_fraction(G, attr)\n",
    "    real = get_attr_edges_real_fraction(G, attr)\n",
    "    \n",
    "    percentages = []\n",
    "    weights = []\n",
    "    for attr1, attr2 in expected:\n",
    "        # En el estudio de homofilia, salteo las aristas entre el mismo valor\n",
    "        if attr1 == attr2: continue\n",
    "        \n",
    "        k = tuple(sorted([attr1, attr2]))\n",
    "        percentage = real.get(k, 0) / expected[k]\n",
    "        weight = attributes[attr1] + attributes[attr2]\n",
    "        percentages.append(percentage)\n",
    "        weights.append(weight)\n",
    "    return (1 - np.average(percentages, weights=weights)) * 100  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b7dc16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "attrs = ['Continent', 'Region', 'Population in thousands (2017)', 'GDP per capita (current US$)']\n",
    "\n",
    "for attr in attrs:\n",
    "    print(f\"El grafo tiene un {homophily_percentage(G, attr):.2f}% de homofilia por la característica {attr}\")\n",
    "    \n",
    "# Donde esperabamos encontrar un gran porcentaje de homofilia era en en la homofilia por continentes, que se cumple. Después de eso, creí que al menos habría una homofilia más alta según población (o según PBI per capita, con la idea de que paises más ricos suelen tener mas viajes entre sí)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd52697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ya dejamos de jugar con los atributos y la homofilia, recuperemos el grafo original!\n",
    "G = nx.from_pandas_edgelist(df, create_using=Graphtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1bc16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\"\"\n",
    "3. Determinar:\n",
    "  a. Puentes globales: {list(nx.bridges(G))}\n",
    "  b. Puentes locales: {[b for b in list(nx.local_bridges(G)) if b[2] != float('inf')]}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9882380",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "4.\n",
    "  a. Determinar un tipo de centralidad que podría ser útil calcular para esta red, justificando.\n",
    "  b. Realizar una representación gráfica de dicha red, considerando la centralidad de los distintos países dada por la métrica del punto a (tamaño de los nodos proporcional a dicha métrica).\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe086b53",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Un análisis que quiero hacer es 'si un día cierro X aeropuerto, cuantos viajes estoy disrumpiendo?', \n",
    "#   esto lo puedo ver con Betweenness: cuáles son los nodos por los que más paso si voy de X a Y?\n",
    "#   y por ende cerrar estos aeroupertos va a hacer que haya que modificar los caminos de X a Y\n",
    "#   (o sea, los aeropuertos adyacentes van a tener que buscar otro lugar en común para hacer escala)\n",
    "#   (esta idea no es tan lejana a buscar puentes locales...)\n",
    "\n",
    "# Voy a graficar solo los nodos que están en el k-core principal, para que el gráfico se pueda ver bien\n",
    "#  (si no, es un choclo de 230 nodos que no se entiende para nada)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "last_core = nx.k_core(G).nodes()\n",
    "centrality = nx.betweenness_centrality(G)\n",
    "nodes = {k:v*10000 for k,v in centrality.items() if k in last_core}\n",
    "\n",
    "plt.title(\"Betweenness Centrality (Main K-Core Nodes)\")\n",
    "nx.draw_networkx(G, nodelist=nodes.keys(), node_size=list(nodes.values()), edgelist=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225571da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "5.\n",
    "  a. Obtener una simulación de un modelado de Erdös-Rényi que corresponda a los parámetros de esta red.\n",
    "  b. Obtener una simulación de un modelado de Preferential Attachment (ley de potencias) que corresponda a los parámetros de esta red.\n",
    "  c. Obtener una representación de anonymous walks tanto de la red original como para las dos simuladas en los puntos a y b. Determinar por distancia coseno cuál sería la simulación más afín.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39958756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def nCr(n,r):\n",
    "    f = math.factorial\n",
    "    return f(n) // f(r) // f(n-r)\n",
    "\n",
    "n_nodes = G.number_of_nodes()\n",
    "n_edges = G.number_of_edges()\n",
    "total_possible_edges = nCr(n_nodes, 2)\n",
    "avg_degree = sum([n[1] for n in G.degree()]) / len(G)\n",
    "\n",
    "erdos = nx.erdos_renyi_graph(n_nodes, n_edges / total_possible_edges)\n",
    "barabara = nx.barabasi_albert_graph(n_nodes, n_edges // n_nodes)\n",
    "\n",
    "grafos = {\n",
    "    \"Original Graph\": G,\n",
    "    \"Erdös-Rényi\": erdos,\n",
    "    \"Barabási-Albert\": barabara\n",
    "}\n",
    "\n",
    "for k,v in grafos.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b3bcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/nd7141/AWE\n",
    "from AnonymousWalkKernel import AnonymousWalks\n",
    "from scipy import spatial\n",
    "\n",
    "length = 5\n",
    "embeds = {}\n",
    "for name, g in grafos.items():\n",
    "    emb, meta = AnonymousWalks(g).embed(steps = length, method = 'sampling', keep_last=True, verbose=False)\n",
    "    embeds[name] = emb\n",
    "\n",
    "simils = {}\n",
    "for name in [\"Erdös-Rényi\",\"Barabási-Albert\"]:\n",
    "    simils[name] = 1 - spatial.distance.cosine(embeds[name], embeds[\"Original Graph\"])\n",
    "\n",
    "for name, simil in simils.items():\n",
    "    print(f\"Similitud Coseno entre {name} y nuestro OG: {simil}\")\n",
    "\n",
    "print(f\"Ganador: {max(simils, key=simils.get)}!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
